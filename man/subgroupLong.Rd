% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fused_longitudinal.R
\name{subgroupLong}
\alias{subgroupLong}
\title{interaction detection for longitudinal outcomes using fused lasso}
\usage{
subgroupLong(x, y, trt, family = c("gaussian", "binomial", "coxph"),
  method = c("weighting", "a_learning"), pi.x = NULL, weights = NULL,
  idx.list = NULL, type.measure = c("mse", "deviance", "class", "auc",
  "mae"), lambda = numeric(0), lasso.penalize = NULL, gamma = 1,
  nlambda = 100L, nfolds = 10L, foldid = NULL, boot = FALSE,
  B = 100L, boot.type = c("replacement", "mofn"), m.frac = 0.9,
  parallel = FALSE, adaptive = FALSE, abs.tol = 1e-05,
  rel.tol = 1e-05, maxit = 250, maxit.cv = 250, rho = NULL, ...)
}
\arguments{
\item{x}{list of design matrices; one for each point in time. If a matrix is given, the design matrix is assumed to
be constant over time
Each row is an observation, each column corresponds to a covariate}

\item{y}{list of numeric response vectors of length nobs(t); one element with a response vector for time t.}

\item{trt}{list of length equal to the number of time periods. each element of trt is a vector of treatment indicators}

\item{family}{"gaussian" for least squares problems, "binomial" for binary response.
"coxph" for time-to-event outcomes}

\item{method}{either \code{"weighting"} for the weighting loss function or \code{"a_learning"} for the
A-learning loss function. The latter may be less sensitive to propensity scores close to 0 or 1}

\item{pi.x}{a vector or list of propensity scores. If left unspecified, will default to constant propensity
based on the sample proportion of treated observations}

\item{weights}{a vector or list of observation weights}

\item{idx.list}{if x is specified as a list (suggesting that the sample sizes vary over time), the user must specify idx.list,
which is a list of patient indices. T t-th list element should be a vector of indices with i-th element being the patient ID
for the i-th row of x[[t]]}

\item{type.measure}{one of c("mse","deviance","class","auc","mae") to be used for cross validation}

\item{lambda}{tuning parameter values for lasso penalty}

\item{lasso.penalize}{list of length equal to the number of time periods. each element of lasso.penalize is a vector
of length equal to the number of variables in x[[t]] (design matrix at time t) with values either 0 or 1 where a 1
in the jth position indicates that the jth variable will be penalized with the lasso and 0 otherwise. Defaults to all
variables being penalized with the lasso.}

\item{gamma}{ratio of fused lasso to lasso tuning parameter}

\item{nlambda}{number of tuning parameter values - default is 100.}

\item{nfolds}{number of folds for cross validation. If given value 0, 1, or NULL, no cross validation will be performed}

\item{foldid}{an optional vector of values between 1 and \code{nfolds} specifying which fold each observation belongs to.}

\item{boot}{logical, whether or not to perform bootstrap for benefit confidence intervals. default is FALSE
for no bootstrap computation}

\item{B}{integer number of resamples for bootstrap - default is 100}

\item{boot.type}{one of \code{"replacement"}, \code{"mofn"}, specifies what type of bootstrap to use: with replacement (standard)
or m-out-of-n bootstrap, in which case the number of samples are taken to be the integer part of
n^\code{m.frac}, where the user specifies \code{m.frac} as some number strictly between 0 and 1. Samples
are taken without replacemet for the m-out-of-n bootstrap}

\item{m.frac}{scalar number strictly between 0 and 1,}

\item{parallel}{boolean indicator of whether or not to utilize parallel computation for cross validation}

\item{adaptive}{should the adaptive ADMM algorithm be used?}

\item{abs.tol}{absolute tolerance for convergence for ADMM. Defaults to 1e-5}

\item{rel.tol}{relative tolerance for convergence for ADMM. Defaults to 1e-5}

\item{maxit}{maximum number of ADMM iterations}

\item{maxit.cv}{maximum number of ADMM iterations for cross validation runs}

\item{rho}{scalar positive number value. This is the ADMM hyperparameter. If unspecified,
code will default to a reasonable choice. Bad values of rho may lead to extraordinarily slow
convergence of ADMM}

\item{...}{other arguments to be passed to cv.fusedlasso}
}
\value{
An object with S3 class "subgroupLong"
}
\description{
interaction detection for longitudinal outcomes using fused lasso
}
\examples{
set.seed(123)
nobs       <- 500
nvars      <- 10
periods    <- 5
sd         <- 2

beta.nz <- rbind(c( 1,    1,    1,    1.5,  1.5),
                 c(-1,   -1,   -1,   -0.5, -0.5),
                 c( 1,    1,    1,   -1,   -1),
                 c( 1,    1,    1,    1,    1),
                 c(-0.5, -0.5, -0.5, -0.5, -0.5))

beta <- data.matrix(rbind(beta.nz, matrix(0, nvars - 5, periods)))

trt <- rbinom(nobs, 1, 0.5)
x   <- matrix(rnorm(nobs * nvars), ncol = nvars); colnames(x) <- paste0("V", 1:ncol(x))
y   <- x \%*\% (beta * 0.5) + (2 * trt - 1) * (x \%*\% beta) +
    matrix(rnorm(nobs * periods, sd = sd), ncol = periods)
y   <- apply(y, 2, function(yy) yy - (2 * trt - 1))

plot(x = NULL, xlim = c(1,periods), ylim = range(y))
for (i in 1:nobs)
{
    lines(x = 1:periods, y = y[i,], col = colors()[i+1])
}

x.list <- rep(list(x), periods)
y.list <- lapply(apply(y, 2, function(x) list(x) ), function(x) x[[1]])
idx.list <- rep(list(1:nrow(x)), periods)

fit <- subgroupLong(x = x.list, y = y.list, idx.list = idx.list,
                    trt = trt, gamma = c(0.05, 0.1, 1, 5, 10))

round(matrix(fit$cv.model$best.cv.fit$beta, ncol = periods), 4)

bfit <- subgroupLong(x = x.list, y = y.list, idx.list = idx.list,
                     trt = trt, gamma = c(0.05, 0.1, 1),
                     boot = TRUE, B = 5L)

plot(bfit)

}
